{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert finish.\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "import tensorflow as tf\n",
    "from itertools import groupby\n",
    "from collections import defaultdict\n",
    "\n",
    "# 因为我装的是CPU版本的，运行起来会有'warning'，解决方法入下，眼不见为净~  \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# 数据源：http://vision.stanford.edu/aditya86/ImageNetDogs/\n",
    "image_filenames = glob.glob( './imagenet-dogs/n02*/*.jpg' )\n",
    "\n",
    "training_dataset = defaultdict(list)\n",
    "testing_dataset = defaultdict(list)\n",
    "\n",
    "image_filename_with_breed = list( map(lambda filename:(filename.split('/')[2], filename), image_filenames) )\n",
    "\n",
    "for dog_breed, breed_images in groupby(image_filename_with_breed, lambda x: x[0]):\n",
    "    for i, breed_image in enumerate(breed_images):\n",
    "        if i % 5 == 0:\n",
    "            testing_dataset[dog_breed].append(breed_image[1])\n",
    "        else:\n",
    "            training_dataset[dog_breed].append(breed_image[1])\n",
    "\n",
    "    breed_training_count = len(training_dataset[dog_breed])\n",
    "    breed_testing_count = len(testing_dataset[dog_breed])\n",
    "    \n",
    "    assert round(breed_testing_count / (breed_training_count + breed_testing_count), 2) > 0.18, \\\n",
    "    \"Not enough testing images.\"\n",
    "    \n",
    "    \n",
    "\n",
    "def imageset_to_records_files(dataset, record_location, resize, \\\n",
    "                              channels = 1, image_type = 'jpg', one_record_count = 100):\n",
    "    writer = None\n",
    "    current_index = 0\n",
    "    image_number = 0\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    for breed, images_filenames in dataset.items():\n",
    "        for image_filename in images_filenames:\n",
    "            if image_number % one_record_count == 0:\n",
    "                if writer:\n",
    "                    writer.close()\n",
    "                    \n",
    "                record_filename = \"{record_location}-{current_index}.tfrecords\". \\\n",
    "                format(record_location=record_location, current_index=current_index)\n",
    "\n",
    "                writer = tf.python_io.TFRecordWriter(record_filename)\n",
    "                current_index += 1\n",
    "                    \n",
    "            image_number += 1\n",
    "\n",
    "            image_file = tf.read_file(image_filename)\n",
    "\n",
    "            try:\n",
    "                if( 'jpg' == image_type ):\n",
    "                    image = tf.image.decode_jpeg(image_file, channels)\n",
    "                elif( 'png' == image_type ):\n",
    "                    image = tf.image.decode_png(image_file, channels)\n",
    "            except:\n",
    "                print('image decode fail: ', image_filename)\n",
    "                continue\n",
    "\n",
    "            resized_image = tf.image.resize_images( image, resize )\n",
    "\n",
    "            #image_bytes = sess.run(tf.cast(resized_image, tf.uint8)).tobytes()\n",
    "            image_loaded = sess.run(tf.cast(resized_image, tf.uint8))\n",
    "            image_bytes = image_loaded.tobytes()\n",
    "            image_label = breed.encode(\"utf-8\")\n",
    "\n",
    "            feature = {\n",
    "                'label':tf.train.Feature(bytes_list=tf.train.BytesList(value = [image_label])),\n",
    "                'image':tf.train.Feature(bytes_list=tf.train.BytesList(value = [image_bytes]))\n",
    "            }\n",
    "            \n",
    "            example = tf.train.Example( features=tf.train.Features(feature = feature) )\n",
    "\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()                \n",
    "\n",
    "# pil_imageset_to_records_files 的速度是 imageset_to_records_file 的好几倍\n",
    "def pil_imageset_to_records_files(dataset, record_location, resize, \\\n",
    "                              channels = 1, image_type = 'jpg', one_record_count = 100):\n",
    "    from PIL import Image\n",
    "    writer = None\n",
    "    current_index = 0\n",
    "    image_number = 0\n",
    "    \n",
    "    for breed, images_filenames in dataset.items():\n",
    "        for image_filename in images_filenames:\n",
    "            if image_number % one_record_count == 0:\n",
    "                if writer:\n",
    "                    writer.close()\n",
    "                    \n",
    "                record_filename = \"{record_location}-{current_index}.tfrecords\". \\\n",
    "                format(record_location=record_location, current_index=current_index)\n",
    "\n",
    "                writer = tf.python_io.TFRecordWriter(record_filename)\n",
    "                current_index += 1\n",
    "                    \n",
    "            image_number += 1\n",
    "\n",
    "            img = None\n",
    "            try:\n",
    "                img = Image.open( image_filename )\n",
    "                if( 1 == channels ):\n",
    "                    img = img.convert('L')\n",
    "                img = img.resize( resize )\n",
    "            \n",
    "            except:\n",
    "                print('image decode fail: ', image_filename)\n",
    "                continue\n",
    "\n",
    "            image_bytes = img.tobytes()\n",
    "            image_label = breed.encode(\"utf-8\")\n",
    "\n",
    "            feature = {\n",
    "                'label':tf.train.Feature(bytes_list=tf.train.BytesList(value = [image_label])),\n",
    "                'image':tf.train.Feature(bytes_list=tf.train.BytesList(value = [image_bytes]))\n",
    "            }\n",
    "            \n",
    "            example = tf.train.Example( features=tf.train.Features(feature = feature) )\n",
    "\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "imageset_to_records_files(testing_dataset, './record_files/test-image/testing-image', [250, 151])\n",
    "pil_imageset_to_records_files(training_dataset, './record_files/train-image/training-image', [250, 151])\n",
    "\n",
    "print('convert finish.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"shuffle_batch:0\", shape=(3, 250, 151, 1), dtype=uint8) Tensor(\"shuffle_batch:1\", shape=(3,), dtype=string)\n",
      "[[[[134]\n",
      "   [134]\n",
      "   [134]\n",
      "   ..., \n",
      "   [199]\n",
      "   [200]\n",
      "   [200]]\n",
      "\n",
      "  [[199]\n",
      "   [199]\n",
      "   [200]\n",
      "   ..., \n",
      "   [172]\n",
      "   [174]\n",
      "   [166]]\n",
      "\n",
      "  [[172]\n",
      "   [184]\n",
      "   [203]\n",
      "   ..., \n",
      "   [100]\n",
      "   [101]\n",
      "   [102]]\n",
      "\n",
      "  ..., \n",
      "  [[ 14]\n",
      "   [ 21]\n",
      "   [ 14]\n",
      "   ..., \n",
      "   [ 75]\n",
      "   [ 82]\n",
      "   [ 79]]\n",
      "\n",
      "  [[ 72]\n",
      "   [ 61]\n",
      "   [ 65]\n",
      "   ..., \n",
      "   [119]\n",
      "   [ 64]\n",
      "   [ 65]]\n",
      "\n",
      "  [[ 40]\n",
      "   [  0]\n",
      "   [ 19]\n",
      "   ..., \n",
      "   [ 39]\n",
      "   [ 44]\n",
      "   [ 53]]]\n",
      "\n",
      "\n",
      " [[[ 36]\n",
      "   [ 36]\n",
      "   [ 36]\n",
      "   ..., \n",
      "   [ 50]\n",
      "   [ 49]\n",
      "   [ 47]]\n",
      "\n",
      "  [[ 47]\n",
      "   [ 47]\n",
      "   [ 47]\n",
      "   ..., \n",
      "   [ 36]\n",
      "   [ 31]\n",
      "   [ 31]]\n",
      "\n",
      "  [[ 31]\n",
      "   [ 34]\n",
      "   [ 35]\n",
      "   ..., \n",
      "   [ 49]\n",
      "   [ 47]\n",
      "   [ 46]]\n",
      "\n",
      "  ..., \n",
      "  [[146]\n",
      "   [161]\n",
      "   [156]\n",
      "   ..., \n",
      "   [162]\n",
      "   [159]\n",
      "   [153]]\n",
      "\n",
      "  [[161]\n",
      "   [176]\n",
      "   [143]\n",
      "   ..., \n",
      "   [108]\n",
      "   [141]\n",
      "   [162]]\n",
      "\n",
      "  [[160]\n",
      "   [169]\n",
      "   [156]\n",
      "   ..., \n",
      "   [125]\n",
      "   [118]\n",
      "   [ 91]]]\n",
      "\n",
      "\n",
      " [[[210]\n",
      "   [210]\n",
      "   [210]\n",
      "   ..., \n",
      "   [191]\n",
      "   [187]\n",
      "   [187]]\n",
      "\n",
      "  [[188]\n",
      "   [188]\n",
      "   [188]\n",
      "   ..., \n",
      "   [205]\n",
      "   [201]\n",
      "   [201]]\n",
      "\n",
      "  [[201]\n",
      "   [201]\n",
      "   [201]\n",
      "   ..., \n",
      "   [174]\n",
      "   [174]\n",
      "   [175]]\n",
      "\n",
      "  ..., \n",
      "  [[222]\n",
      "   [224]\n",
      "   [224]\n",
      "   ..., \n",
      "   [201]\n",
      "   [200]\n",
      "   [215]]\n",
      "\n",
      "  [[215]\n",
      "   [198]\n",
      "   [209]\n",
      "   ..., \n",
      "   [210]\n",
      "   [210]\n",
      "   [214]]\n",
      "\n",
      "  [[221]\n",
      "   [221]\n",
      "   [222]\n",
      "   ..., \n",
      "   [219]\n",
      "   [218]\n",
      "   [218]]]] [b'n02094258-Norwich_terrier' b'n02104029-kuvasz'\n",
      " b'n02094258-Norwich_terrier']\n",
      "float_image_batch shape: (3, 250, 151, 1)\n",
      "float_image_batch:  [[[[ 0.10196079]\n",
      "   [ 0.10980393]\n",
      "   [ 0.1137255 ]\n",
      "   ..., \n",
      "   [ 0.11764707]\n",
      "   [ 0.11764707]\n",
      "   [ 0.10196079]]\n",
      "\n",
      "  [[ 0.10196079]\n",
      "   [ 0.1254902 ]\n",
      "   [ 0.12156864]\n",
      "   ..., \n",
      "   [ 0.10588236]\n",
      "   [ 0.10980393]\n",
      "   [ 0.10588236]]\n",
      "\n",
      "  [[ 0.10588236]\n",
      "   [ 0.10588236]\n",
      "   [ 0.09019608]\n",
      "   ..., \n",
      "   [ 0.14117648]\n",
      "   [ 0.08627451]\n",
      "   [ 0.09803922]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.10980393]\n",
      "   [ 0.19607845]\n",
      "   [ 0.0627451 ]\n",
      "   ..., \n",
      "   [ 0.20392159]\n",
      "   [ 0.20784315]\n",
      "   [ 0.21960786]]\n",
      "\n",
      "  [[ 0.16862746]\n",
      "   [ 0.14117648]\n",
      "   [ 0.09019608]\n",
      "   ..., \n",
      "   [ 0.10588236]\n",
      "   [ 0.16078432]\n",
      "   [ 0.10196079]]\n",
      "\n",
      "  [[ 0.08627451]\n",
      "   [ 0.09803922]\n",
      "   [ 0.09411766]\n",
      "   ..., \n",
      "   [ 0.09019608]\n",
      "   [ 0.09411766]\n",
      "   [ 0.09411766]]]\n",
      "\n",
      "\n",
      " [[[ 0.1254902 ]\n",
      "   [ 0.15294118]\n",
      "   [ 0.1254902 ]\n",
      "   ..., \n",
      "   [ 0.19215688]\n",
      "   [ 0.12156864]\n",
      "   [ 0.24705884]]\n",
      "\n",
      "  [[ 0.14509805]\n",
      "   [ 0.24313727]\n",
      "   [ 0.13725491]\n",
      "   ..., \n",
      "   [ 0.29019609]\n",
      "   [ 0.19215688]\n",
      "   [ 0.16078432]]\n",
      "\n",
      "  [[ 0.10980393]\n",
      "   [ 0.10588236]\n",
      "   [ 0.10196079]\n",
      "   ..., \n",
      "   [ 0.3137255 ]\n",
      "   [ 0.24313727]\n",
      "   [ 0.18039216]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.76470596]\n",
      "   [ 0.75294125]\n",
      "   [ 0.75686282]\n",
      "   ..., \n",
      "   [ 0.48235297]\n",
      "   [ 0.49019611]\n",
      "   [ 0.49411768]]\n",
      "\n",
      "  [[ 0.48235297]\n",
      "   [ 0.4784314 ]\n",
      "   [ 0.4784314 ]\n",
      "   ..., \n",
      "   [ 0.71764708]\n",
      "   [ 0.71372551]\n",
      "   [ 0.70980394]]\n",
      "\n",
      "  [[ 0.70980394]\n",
      "   [ 0.70980394]\n",
      "   [ 0.71372551]\n",
      "   ..., \n",
      "   [ 0.49019611]\n",
      "   [ 0.49411768]\n",
      "   [ 0.49411768]]]\n",
      "\n",
      "\n",
      " [[[ 0.35294119]\n",
      "   [ 0.32156864]\n",
      "   [ 0.29411766]\n",
      "   ..., \n",
      "   [ 0.10196079]\n",
      "   [ 0.09803922]\n",
      "   [ 0.09803922]]\n",
      "\n",
      "  [[ 0.09803922]\n",
      "   [ 0.10588236]\n",
      "   [ 0.10980393]\n",
      "   ..., \n",
      "   [ 0.20000002]\n",
      "   [ 0.16862746]\n",
      "   [ 0.14509805]]\n",
      "\n",
      "  [[ 0.18039216]\n",
      "   [ 0.19607845]\n",
      "   [ 0.17647059]\n",
      "   ..., \n",
      "   [ 0.33333334]\n",
      "   [ 0.28627452]\n",
      "   [ 0.36078432]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.58431375]\n",
      "   [ 0.60392159]\n",
      "   [ 0.66666669]\n",
      "   ..., \n",
      "   [ 0.3921569 ]\n",
      "   [ 0.41960788]\n",
      "   [ 0.53333336]]\n",
      "\n",
      "  [[ 0.42352945]\n",
      "   [ 0.45098042]\n",
      "   [ 0.44313729]\n",
      "   ..., \n",
      "   [ 0.54509807]\n",
      "   [ 0.58039218]\n",
      "   [ 0.56862748]]\n",
      "\n",
      "  [[ 0.60000002]\n",
      "   [ 0.58823532]\n",
      "   [ 0.56470591]\n",
      "   ..., \n",
      "   [ 0.19607845]\n",
      "   [ 0.21176472]\n",
      "   [ 0.22352943]]]]\n",
      "(3, 125, 76, 32)\n",
      "(3, 63, 38, 32)\n",
      "(3, 63, 38, 64)\n",
      "(3, 32, 19, 64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "\n",
    "labels = list(map(lambda c: c.split(\"/\")[-1], blob.glob(\"./imagenet-dogs/*\")))\n",
    "train_labels = tf.map_fn(lambda l: tf.where(tf.equal(labels, l))[0, 0:1][0], label_batch, dtype=tf.int64)\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# records_path: './record_files/train-image/*.tfrecords'\n",
    "# image_shape: [250, 151, 1]\n",
    "# batch_size: 3\n",
    "def read_images_from_tfrecords(records_path, image_shape, batch_size):\n",
    "    file_path = tf.train.match_filenames_once( records_path )\n",
    "    file_queue = tf.train.string_input_producer( file_path )\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized = reader.read( file_queue )\n",
    "\n",
    "    feature = {\n",
    "        'label':tf.FixedLenFeature([], tf.string),\n",
    "        'image':tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "\n",
    "    features = tf.parse_single_example( serialized, features = feature )\n",
    "\n",
    "    record_image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    label = tf.cast( features['label'], tf.string )\n",
    "\n",
    "    image = tf.reshape(record_image, [250, 151, 1])\n",
    "\n",
    "    min_after_dequeue = 10\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    image_batch, label_batch = tf.train.shuffle_batch([image, label], batch_size = batch_size, capacity = capacity, min_after_dequeue = min_after_dequeue)\n",
    "    return image_batch, label_batch\n",
    "    \n",
    "\n",
    "batch_size = 3\n",
    "image_batch, label_batch = read_images_from_tfrecords('./record_files/train-image/*.tfrecords', [250, 151, 1], batch_size)\n",
    "\n",
    "# 初始化  \n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())  \n",
    "sess.run(init_op) \n",
    "coord = tf.train.Coordinator() \n",
    "threads = tf.train.start_queue_runners( sess = sess, coord = coord ) \n",
    "\n",
    "# print('file_path run: ', sess.run(file_path))\n",
    "# print('record_image shape:', record_image.get_shape())\n",
    "# print('record_image run: ', sess.run(record_image))\n",
    "\n",
    "# print(image, label)\n",
    "# print(sess.run(image), sess.run(label))\n",
    "print(image_batch, label_batch)\n",
    "print(sess.run(image_batch), sess.run(label_batch))\n",
    "\n",
    "\n",
    "float_image_batch = tf.image.convert_image_dtype(image_batch, tf.float32)\n",
    "print('float_image_batch shape:', float_image_batch.get_shape())\n",
    "print('float_image_batch: ', sess.run(float_image_batch))\n",
    "\n",
    "\n",
    "\n",
    "#'''\n",
    "conv2d_layer_one = tf.contrib.layers.convolution2d(\n",
    "    float_image_batch, \n",
    "    num_outputs = 32, \n",
    "    kernel_size = (5, 5), \n",
    "    activation_fn = tf.nn.relu,\n",
    "    weights_initializer = tf.random_normal_initializer,\n",
    "    stride = (2, 2),\n",
    "    data_format = 'NHWC',\n",
    "    trainable = True\n",
    ")\n",
    "\n",
    "pool_layer_one = tf.nn.max_pool(conv2d_layer_one,\n",
    "                               ksize = [1, 2, 2, 1],\n",
    "                               strides = [1, 2, 2, 1],\n",
    "                               padding = 'SAME')\n",
    "\n",
    "print( conv2d_layer_one.get_shape() )\n",
    "print( pool_layer_one.get_shape() )\n",
    "#'''\n",
    "\n",
    "#'''\n",
    "conv2d_layer_two = tf.contrib.layers.convolution2d(\n",
    "    pool_layer_one, \n",
    "    num_outputs = 64, \n",
    "    kernel_size = (5, 5), \n",
    "    activation_fn = tf.nn.relu,\n",
    "    weights_initializer = tf.random_normal_initializer,\n",
    "    stride = (1, 1),\n",
    "    data_format = 'NHWC',\n",
    "    trainable = True\n",
    ")\n",
    "\n",
    "pool_layer_two = tf.nn.max_pool(conv2d_layer_two,\n",
    "                               ksize = [1, 2, 2, 1],\n",
    "                               strides = [1, 2, 2, 1],\n",
    "                               padding = 'SAME')\n",
    "\n",
    "print( conv2d_layer_two.get_shape() )\n",
    "print( pool_layer_two.get_shape() )\n",
    "#'''\n",
    "\n",
    "\n",
    "flattened_layer_two = tf.reshape( pool_layer_tow, [batch_size, -1] )\n",
    "print( flattened_layer_two.get_shape() )\n",
    "\n",
    "hidden_layer_three = tf.contrib.layers.fully_connected(\n",
    "    flattened_layer_two, \n",
    "    512,\n",
    "    weight_init = lambda i, dtype: tf.truncated_normal( [38912, 512], stddev = 0.1 ),\n",
    "    activation_fn = tf.nn.relu\n",
    ")\n",
    "\n",
    "hidden_layer_three = tf.nn.dropout( hidden_layer_three, 0.1 )\n",
    "final_fully_connected = tf.contrib.layers.fully_connected(\n",
    "    hidden_layer_three,\n",
    "    120,\n",
    "    weight_init = lambda i, dtype: tf.truncated_normal( [512, 120], stddev = 0.1 )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#关闭线程  \n",
    "coord.request_stop()  \n",
    "coord.join(threads)  \n",
    "sess.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.contrib.layers.convolution2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python_ve_tf",
   "language": "python",
   "name": "ve_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

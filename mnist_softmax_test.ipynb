{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- do_train: start -----------------\n",
      "0 -W:  <tensorflow.python.ops.variables.Variable object at 0x7f4ef6c90ba8>\n",
      "1 _W:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "1_0 cost:  Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]]\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[0 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]]\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]]\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]]\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]]\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n",
      "11_1 features_in:  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "11_1 labels_in:  [[0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "2_0 cost:  Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
      "2 _W:  [[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "def _read32(bytestream):\n",
    "    dt = numpy.dtype(numpy.uint32).newbyteorder('>')\n",
    "    return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "def _dense_to_one_hot(labels_dense, num_classes):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = numpy.arange(num_labels) * num_classes\n",
    "    labels_one_hot = numpy.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    labels_one_hot = labels_one_hot.astype(numpy.float32)\n",
    "    return labels_one_hot\n",
    "\n",
    "def input_mnist_data(file_path):\n",
    "    with gfile.Open(file_path, 'rb') as bytestream:\n",
    "        magic = _read32(bytestream)\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Invalid magic number %d in MNIST image file: %s' % (magic, file_path))\n",
    "\n",
    "        num_images = _read32(bytestream)\n",
    "        rows = _read32(bytestream)\n",
    "        cols = _read32(bytestream)\n",
    "        buf = bytestream.read(rows * cols * num_images)\n",
    "        data = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "        data = data.reshape(num_images, rows * cols * 1)\n",
    "        data = data.astype(numpy.float32)\n",
    "        return data\n",
    "    \n",
    "def input_mnist_label(file_path):    \n",
    "    with gfile.Open(file_path, 'rb') as bytestream:\n",
    "        magic = _read32(bytestream)\n",
    "        if magic != 2049:\n",
    "            raise ValueError( 'Invalid magic number %d in MNIST label file: %s' % (magic, file_path) )\n",
    "        \n",
    "        num_items = _read32(bytestream)\n",
    "        buf = bytestream.read(num_items)\n",
    "        labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "        return _dense_to_one_hot(labels, 10)\n",
    "\n",
    "\n",
    "def _get_next_data(image_file, label_file, batch_size):\n",
    "    train_data = input_mnist_data(image_file)\n",
    "    train_label = input_mnist_label(label_file)\n",
    "    step = 0\n",
    "    for step in range( len(train_data) // batch_size ):\n",
    "        begin = step * batch_size\n",
    "        end = begin + batch_size\n",
    "        if end >= len(train_data):\n",
    "            end = len(train_data) - 1\n",
    "\n",
    "        yield train_data[begin : end], train_label[begin : end]\n",
    "\n",
    "\n",
    "def inference(features):\n",
    "    combine_input = tf.matmul(features, _W) + _b\n",
    "    inference = tf.nn.softmax( combine_input )      \n",
    "    inference = tf.Print(inference, [inference, combine_input], '******* inference: ')\n",
    "    return inference\n",
    "    \n",
    "print( '-------------- do_train: start -----------------' )\n",
    "\n",
    "\n",
    "_W = tf.Variable(tf.zeros([784, 10]), name = 'weights')\n",
    "_b = tf.Variable(tf.zeros([10]), name = 'bias')    \n",
    "\n",
    "print( '0 -W: ', _W )\n",
    "       \n",
    "train_data_generator = _get_next_data( './MNIST_data/train-images.idx3-ubyte', \n",
    "                                      './MNIST_data/train-labels.idx1-ubyte', 5 )\n",
    "\n",
    "# features, labels = next( data_generator )\n",
    "# print( '0 label: ', labels )\n",
    "features = tf.placeholder(\"float\", shape=[None, 784])\n",
    "labels = tf.placeholder(\"float\", shape=[None, 10])\n",
    "\n",
    "#combine_input = tf.matmul(features, _W) + _b\n",
    "#label_predicted = tf.nn.softmax( combine_input )\n",
    "label_predicted = inference( features )\n",
    "#print( '0 label_predicted: ', label_predicted )\n",
    "\n",
    "\n",
    "cost = -tf.reduce_sum( labels * tf.log( label_predicted ) )\n",
    "# cost = tf.Print(cost, [cost], '0 ****************** cost: ')\n",
    "# cost = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(label_predicted, labels_t) )\n",
    "\n",
    "with tf.control_dependencies([tf.Print(cost, [cost], '0 ****************** cost: ')]):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize( cost )\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run( tf.initialize_all_variables() )\n",
    "\n",
    "\n",
    "print( '1 _W: ', sess.run(_W) )\n",
    "print( '1_0 cost: ', cost )\n",
    "# print( '1_1 cost: ', sess.run(cost) )\n",
    "\n",
    "#print( '1_1 label_predicted: ', sess.run(label_predicted) )\n",
    "#print( '1_1 labels_t: ', sess.run(labels_t) )\n",
    "for i in range(10):\n",
    "    features_in, labels_in = next( data_generator )\n",
    "    print( '11_1 features_in: ', features_in )\n",
    "    print( '11_1 labels_in: ', labels_in )\n",
    "    \n",
    "    sess.run( train_step, feed_dict={features: features_in, labels: labels_in} )\n",
    "    # print( '2_1 cost: ', cost.eval(feed_dict={features: features_in, labels: labels_in}) )\n",
    "        \n",
    "print( '2_0 cost: ', cost )\n",
    "print( '2 _W: ', sess.run(_W) )\n",
    "    \n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(label_predicted, 1), tf.argmax(labels, 1))\n",
    "#print( '3 correct_prediction: ', sess.run(correct_prediction) )\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))   \n",
    "#print( '3 accuracy: ', sess.run(accuracy) )    \n",
    "\n",
    "test_data_generator = _get_next_data( './MNIST_data/t10k-images.idx3-ubyte', \n",
    "                                      './MNIST_data/t10k-labels.idx1-ubyte', 5 )\n",
    "test_features, test_labels = next( test_data_generator )\n",
    "print( accuracy.eval(feed_dict={features: test_features, labels: test_labels}) )\n",
    "    \n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f4ef6f84ba8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 171, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 976, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3378, in get_controller\n",
      "    % type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'weakref'> objects\n"
     ]
    }
   ],
   "source": [
    "label_predicted = [[ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1],\n",
    "   [ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1]]\n",
    "# labels_t = [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "labels_t = [5, 0]\n",
    "    \n",
    "cost = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(label_predicted, labels_t) )\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "with tf.control_dependencies([tf.Print(cost, [cost], \"###\")]):\n",
    "    sess.run(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- do_train: start -----------------\n",
      "file_path =  ['/home/yangyuqi/work/tf_algorithm_example/data_source/Titanic_train.csv'] \n",
      "\n",
      "Tensor(\"ReaderRead_2:0\", shape=(), dtype=string) Tensor(\"ReaderRead_2:1\", shape=(), dtype=string)\n",
      "features_0 tensor.shape = [10  5], tensor = [[  1.   0.   0.   0.  54.]\n",
      " [  0.   0.   1.   1.   0.]\n",
      " [  0.   0.   1.   1.   0.]\n",
      " [  1.   0.   0.   0.  40.]\n",
      " [  1.   0.   0.   0.  19.]\n",
      " [  0.   0.   1.   0.  39.]\n",
      " [  0.   0.   1.   0.   0.]\n",
      " [  0.   1.   0.   0.  66.]\n",
      " [  1.   0.   0.   0.  28.]\n",
      " [  0.   0.   1.   0.   0.]]\n",
      "\n",
      "label_0 tensor.shape = [10  1], tensor = [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]]\n",
      "\n",
      "step_0 loss:  tensor.shape = [], tensor = 1.0820581912994385\n",
      "\n",
      "training end. step_9 final loss:  tensor.shape = [], tensor = 0.5206577181816101\n",
      "\n",
      "save_path is:  /tmp/ML_Sigma_Regression.vari\n",
      "At evaluate, the __W tensor.shape = [5 1], tensor = [[ 0.00112222]\n",
      " [ 0.00130765]\n",
      " [-0.00388342]\n",
      " [ 0.01107831]\n",
      " [-0.02698931]]\n",
      "\n",
      "At evaluate, the __b tensor.shape = [], tensor = -0.0014535515801981091\n",
      "\n",
      "At evaluate, test_features tensor.shape = [10  5], tensor = [[  1.   0.   0.   0.   0.]\n",
      " [  0.   1.   0.   0.  42.]\n",
      " [  0.   1.   0.   1.  32.]\n",
      " [  0.   1.   0.   0.   0.]\n",
      " [  0.   0.   1.   1.  27.]\n",
      " [  0.   0.   1.   0.   0.]\n",
      " [  0.   1.   0.   0.  19.]\n",
      " [  0.   1.   0.   0.  27.]\n",
      " [  0.   0.   1.   0.  22.]\n",
      " [  0.   0.   1.   0.  51.]]\n",
      "\n",
      "At evaluate, test_label tensor.shape = [10  1], tensor = [[ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "\n",
      "evaluate_result tensor.shape = [], tensor = 0.8999999761581421\n",
      "\n",
      "----------------- do_train: finish -----------------\n",
      "-------------- do_evaluate: start -----------------\n",
      "\n",
      "file_path =  ['/home/yangyuqi/work/tf_algorithm_example/data_source/Titanic_train.csv'] \n",
      "\n",
      "Tensor(\"ReaderRead_3:0\", shape=(), dtype=string) Tensor(\"ReaderRead_3:1\", shape=(), dtype=string)\n",
      "At evaluate, the __W tensor.shape = [5 1], tensor = [[ 0.00112222]\n",
      " [ 0.00130765]\n",
      " [-0.00388342]\n",
      " [ 0.01107831]\n",
      " [-0.02698931]]\n",
      "\n",
      "At evaluate, the __b tensor.shape = [], tensor = -0.0014535515801981091\n",
      "\n",
      "At evaluate, test_features tensor.shape = [10  5], tensor = [[  0.   0.   1.   0.   0.]\n",
      " [  0.   1.   0.   0.  34.]\n",
      " [  0.   0.   1.   1.  38.]\n",
      " [  0.   0.   1.   1.  31.]\n",
      " [  1.   0.   0.   0.  28.]\n",
      " [  1.   0.   0.   0.  42.]\n",
      " [  0.   0.   1.   1.   8.]\n",
      " [  0.   1.   0.   0.  35.]\n",
      " [  0.   0.   1.   0.   0.]\n",
      " [  0.   0.   1.   0.   0.]]\n",
      "\n",
      "At evaluate, test_label tensor.shape = [10  1], tensor = [[ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "\n",
      "accuracy_rate tensor.shape = [], tensor = 0.699999988079071\n",
      "\n",
      "----------------- do_evaluate: finish -----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################## 机器学习对数几率回归类 ##############################\n",
    "# Author: 杨玉奇\n",
    "# email: yangyuqi@sina.com\n",
    "# url: https://github.com/jerryyyq/tf_algorithm_example\n",
    "# copyright yangyuqi\n",
    "# 著作权归作者 杨玉奇 所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n",
    "# date: 2017-09-13\n",
    "###################################################################\n",
    "import tensorflow as tf\n",
    "\n",
    "from common import *\n",
    "from ML_Model import ML_Model\n",
    "\n",
    "\n",
    "class ML_Sigma_Regression( ML_Model ):\n",
    "    def __init__(self):\n",
    "        ML_Model.__init__(self)\n",
    "\n",
    "        self.__W = tf.Variable(tf.zeros([5, 1]), name = 'weights')\n",
    "        self.__b = tf.Variable(0., name = 'bias')\n",
    "    \n",
    "        \n",
    "    def combine_inputs(self, features):\n",
    "        return tf.matmul(features, self.__W) + self.__b\n",
    "    \n",
    "    def inference(self, features):\n",
    "        return tf.sigmoid( self.combine_inputs(features) )\n",
    "    \n",
    "    def loss(self, features, label):\n",
    "        label_predicted = self.combine_inputs(features)\n",
    "        return tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(label_predicted, label) )\n",
    "    \n",
    "    \n",
    "    def inputs(self, file_name = [], batch_size = 10):\n",
    "        passenger_id, survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = \\\n",
    "        read_csv(batch_size, file_name, [[0.0], [0.0], [0], [''], [''], [0.0], [0.0], [0.0], [''], [0.0], [''], ['']])\n",
    "        # print('-----inputs: ', passenger_id, survived, pclass, name)\n",
    "\n",
    "        # return passenger_id, survived\n",
    "        \n",
    "        is_first_class = tf.to_float(tf.equal(pclass, [1]))\n",
    "        is_second_class = tf.to_float(tf.equal(pclass, [2]))\n",
    "        is_third_class = tf.to_float(tf.equal(pclass, [3]))\n",
    "\n",
    "        gender = tf.to_float(tf.equal(sex, ['female']))\n",
    "\n",
    "        features = tf.transpose(tf.pack([is_first_class, is_second_class, is_third_class, gender, age]))\n",
    "        label = tf.reshape(survived, [batch_size, 1])\n",
    "        return features, label \n",
    "        \n",
    "        \n",
    "    def train(self, loss):    \n",
    "        learning_rate = 0.01\n",
    "        return tf.train.GradientDescentOptimizer( learning_rate ).minimize( loss )\n",
    "\n",
    "    \n",
    "    def evaluate(self, test_features, test_label):\n",
    "        echo_tensor(self._sess, self.__W, 'At evaluate, the __W')\n",
    "        echo_tensor(self._sess, self.__b, 'At evaluate, the __b')\n",
    "        echo_tensor(self._sess, test_features, 'At evaluate, test_features')\n",
    "        echo_tensor(self._sess, test_label, 'At evaluate, test_label')\n",
    "        \n",
    "        label_predicted = tf.cast( self.inference(test_features) > 0.5, tf.float32 )\n",
    "        \n",
    "        return tf.reduce_mean( tf.cast(tf.equal(label_predicted, test_label), tf.float32) )\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    one_ml = ML_Sigma_Regression()\n",
    "    # data from: https://www.kaggle.com/c/titanic/data\n",
    "    one_ml.do_train( 10, ['data_source/Titanic_train.csv'] )\n",
    "\n",
    "    one_ml.do_evaluate( ['data_source/Titanic_train.csv'] )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5]\n",
      "f:  [[1.0, 0.0, 0.0, 1.0, 35.0], [0.0, 0.0, 1.0, 1.0, 26.0], [0.0, 0.0, 1.0, 0.0, 0.0]]\n",
      "tf_f shape:  [3 5]\n",
      "[[  1.   0.   0.   1.  35.]\n",
      " [  0.   0.   1.   1.  26.]\n",
      " [  0.   0.   1.   0.   0.]]\n",
      "tf_f,l:  [array([[  1.,   0.,   0.,   1.,  35.],\n",
      "       [  0.,   0.,   1.,   1.,  26.],\n",
      "       [  0.,   0.,   1.,   0.,   0.]], dtype=float32), array([[ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.]], dtype=float32)]\n",
      "f_pack:  Tensor(\"pack:0\", shape=(3, 3), dtype=float32) [[ 1.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  1.  1.]]\n",
      "f_pack_tr:  [[ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n",
      "shape(tf_pack):  Tensor(\"Shape_2:0\", shape=(2,), dtype=int32) [3 3]\n",
      "[array([[ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]], dtype=float32), array([[ 0.69314718],\n",
      "       [ 0.69314718],\n",
      "       [ 0.69314718]], dtype=float32), 0.69314718]\n",
      "[array([[ 0.00166667],\n",
      "       [ 0.        ],\n",
      "       [-0.00333333],\n",
      "       [ 0.        ],\n",
      "       [ 0.015     ]], dtype=float32), -0.0016666667]\n",
      "0.686475\n"
     ]
    }
   ],
   "source": [
    "# 中间计算数据样例展示\n",
    "import tensorflow as tf\n",
    "\n",
    "f = [[1., 0., 0., 1., 35.],\n",
    " [0., 0., 1., 1., 26.],\n",
    " [0., 0., 1., 0., 0.]]\n",
    "\n",
    "l = [[ 1.], [ 0.], [ 0.]]\n",
    "\n",
    "tf_f = tf.convert_to_tensor(f)\n",
    "tf_l = tf.convert_to_tensor(l)\n",
    "\n",
    "\n",
    "f1 = [1., 0., 0.]\n",
    "f2 = [0., 0., 0.]\n",
    "f3 = [0., 1., 1.]\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print( sess.run(tf.shape(f)) )\n",
    "    # print( sess.run(f) ) --> Can not convert a list into a Tensor or Operation.\n",
    "    print('f: ', f)\n",
    "    print( 'tf_f shape: ', sess.run(tf.shape(tf_f)) )\n",
    "    print( sess.run(tf_f) )\n",
    "    \n",
    "    print( 'tf_f,l: ', sess.run([tf_f, tf_l]) )\n",
    "\n",
    "    f_pack = tf.pack([f1, f2, f3])\n",
    "    print( 'f_pack: ', f_pack, sess.run(f_pack) )\n",
    "    f_pack_tr = tf.transpose(f_pack)\n",
    "    print( 'f_pack_tr: ', sess.run(f_pack_tr) )\n",
    "    print( 'shape(tf_pack): ', tf.shape(f_pack), sess.run(tf.shape(f_pack)) )\n",
    "\n",
    "    \n",
    "    W = tf.Variable(tf.zeros([5, 1]), name = 'weights')\n",
    "    b = tf.Variable(0., name = 'bias')\n",
    "    sess.run( tf.initialize_all_variables() )\n",
    "    \n",
    "    label_predicted = tf.matmul(f, W) + b   # tf_f, f total OK!\n",
    "    sig = tf.nn.sigmoid_cross_entropy_with_logits(label_predicted, l)\n",
    "    loss = tf.reduce_mean( sig ) # tf_l, l total OK!\n",
    "    print( sess.run([label_predicted, sig, loss]) )\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    cost = tf.train.GradientDescentOptimizer( learning_rate ).minimize( loss )\n",
    "    sess.run(cost)\n",
    "    print(sess.run([W, b]))\n",
    "    print(sess.run(loss))\n",
    "    \n",
    "    sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.shape(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- do_train: start -----------------\n",
      "(10, 125, 76, 32)\n",
      "(10, 63, 38, 32)\n",
      "(10, 63, 38, 64)\n",
      "(10, 32, 19, 64)\n",
      "(10, 38912)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape (10, 250, 151, 1) must have rank 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    562\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0mnew_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_same_rank\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\n\u001b[0;32m--> 609\u001b[0;31m             \"Shapes %s and %s must have the same rank\" % (self, other))\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (10, 250, 151, 1) and (?, ?) must have the same rank",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    569\u001b[0m         raise ValueError(\"Shapes %s and %s are not compatible\" %\n\u001b[0;32m--> 570\u001b[0;31m                          (self, other))\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (10, 250, 151, 1) and (?, ?) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-03b9aa1cb6aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mone_ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mML_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m151\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# data from: https://archive.ics.uci.edu/ml/datasets/Iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mone_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_train\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m  \u001b[0;31m# 10000 次可以得到 80% 的准确率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mone_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_evaluate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/tf_algorithm_example/ML_Model.py\u001b[0m in \u001b[0;36mdo_train\u001b[0;34m(self, training_steps, train_file_name, train_batch_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfeature_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_size\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeature_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-03b9aa1cb6aa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, feature_batch, label_batch)\u001b[0m\n\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeature_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-03b9aa1cb6aa>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, features, label)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mlabel_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-03b9aa1cb6aa>\u001b[0m in \u001b[0;36mcombine_inputs\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcombine_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_W\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#def inference(self, features):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1207\u001b[0m                                    \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                                    \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                                    name=name)\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0msparse_matmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_mat_mul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m   \"\"\"\n\u001b[1;32m   1177\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[0;32m-> 1178\u001b[0;31m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1179\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    702\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    703\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    705\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2260\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2262\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2263\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2264\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1700\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1701\u001b[0m                          % op.type)\n\u001b[0;32m-> 1702\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/common_shapes.py\u001b[0m in \u001b[0;36mmatmul_shape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmatmul_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;34m\"\"\"Shape function for a MatMul op.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m   \u001b[0ma_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m   \u001b[0mtranspose_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0mb_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    639\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwith_rank_at_least\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (10, 250, 151, 1) must have rank 2"
     ]
    }
   ],
   "source": [
    "######################## 机器学习 CNN 类 ##############################\n",
    "# Author: 杨玉奇\n",
    "# email: yangyuqi@sina.com\n",
    "# url: https://github.com/jerryyyq/tf_algorithm_example\n",
    "# copyright yangyuqi\n",
    "# 著作权归作者 杨玉奇 所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n",
    "# date: 2018-03-28\n",
    "###################################################################\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from common import *\n",
    "from ML_Model import ML_Model\n",
    "from img_to_tf_record import Img2TFRecord\n",
    "\n",
    "class ML_CNN( ML_Model ):\n",
    "    def __init__(self, feature_shape, label_number):\n",
    "        # feature_number: 一个图像的 长 × 宽 × channels\n",
    "        ML_Model.__init__(self)\n",
    "\n",
    "        self.__label_number = label_number\n",
    "        self.__feature_shape = feature_shape\n",
    "        feature_shape.append(label_number)\n",
    "        self._W = tf.Variable(tf.zeros(feature_shape), name = 'weights')\n",
    "        self._b = tf.Variable(tf.zeros([label_number]), name = 'bias')\n",
    "        self.__img_set = Img2TFRecord('/home/yangyuqi/Downloads/Images', '/tmp/tf_out/tmp1')\n",
    "\n",
    "\n",
    "    def combine_inputs(self, features):\n",
    "        return tf.matmul(features, self._W) + self._b\n",
    "\n",
    "    #def inference(self, features):\n",
    "        #return tf.nn.softmax( self.combine_inputs(features) )\n",
    "    def inference(x, num_class):\n",
    "        with tf.variable_scope('softmax'):\n",
    "            dtype = x.dtype.base_dtype\n",
    "            # Set up the requested initialization.\n",
    "            init_mean = 0.0\n",
    "            init_stddev = 0.0\n",
    "            weights = tf.get_variable('weights',\n",
    "                                [x.get_shape()[1], num_class], initializer=init_ops.random_normal_initializer(init_mean, init_stddev, dtype=dtype), dtype=dtype)\n",
    "            biases = tf.get_variable('bias', [num_class], initializer=init_ops.random_normal_initializer(init_mean, init_stddev, dtype=dtype), dtype=dtype)\n",
    "\n",
    "            logits = tf.nn.xw_plus_b(x, weights, biases)\n",
    "            return logits\n",
    "\n",
    "    \n",
    "    def loss(self, features, label):\n",
    "        label_predicted = self.combine_inputs(features)\n",
    "        return tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(logits = label_predicted, labels = label) )\n",
    "    \n",
    "    \n",
    "    def inputs(self, file_name = [], batch_size = 10):\n",
    "        if file_name[0] == 'train':\n",
    "            image_batch, label_batch = self.__img_set.read_train_images_from_tf_records([250, 151, 1], batch_size)\n",
    "        else:\n",
    "            image_batch, label_batch = self.__img_set.read_test_images_from_tf_records([250, 151, 1], batch)\n",
    "\n",
    "        # image_batch2 = tf.reshape( image_batch, (batch_size, 250*151*1) )\n",
    "        label_batch2 = tf.one_hot( label_batch, self.__label_number, 1, 0 )\n",
    "        return image_batch, label_batch2\n",
    "        \n",
    "        \n",
    "    def train(self, feature_batch, label_batch):\n",
    "\n",
    "        conv2d_layer_one = tf.contrib.layers.convolution2d(\n",
    "            feature_batch, \n",
    "            num_outputs = 32, \n",
    "            kernel_size = (5, 5), \n",
    "            activation_fn = tf.nn.relu,\n",
    "            weights_initializer = tf.random_normal_initializer(),\n",
    "            stride = (2, 2),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "        pool_layer_one = tf.nn.max_pool(conv2d_layer_one,\n",
    "                                       ksize = [1, 2, 2, 1],\n",
    "                                       strides = [1, 2, 2, 1],\n",
    "                                       padding = 'SAME')\n",
    "\n",
    "        print( conv2d_layer_one.get_shape() )\n",
    "        print( pool_layer_one.get_shape() )\n",
    "\n",
    "\n",
    "        conv2d_layer_two = tf.contrib.layers.convolution2d(\n",
    "            pool_layer_one, \n",
    "            num_outputs = 64, \n",
    "            kernel_size = (5, 5), \n",
    "            activation_fn = tf.nn.relu,\n",
    "            weights_initializer = tf.random_normal_initializer(),\n",
    "            stride = (1, 1),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "        pool_layer_two = tf.nn.max_pool(conv2d_layer_two,\n",
    "                                       ksize = [1, 2, 2, 1],\n",
    "                                       strides = [1, 2, 2, 1],\n",
    "                                       padding = 'SAME')\n",
    "\n",
    "        print( conv2d_layer_two.get_shape() )\n",
    "        print( pool_layer_two.get_shape() )\n",
    "\n",
    "\n",
    "        flattened_layer_two = tf.reshape( pool_layer_two, [feature_batch.get_shape().as_list()[0], -1] )\n",
    "        print( flattened_layer_two.get_shape() )\n",
    "\n",
    "        hidden_layer_three = tf.contrib.layers.fully_connected(\n",
    "            flattened_layer_two, \n",
    "            512,\n",
    "            weights_initializer = lambda i, dtype: tf.truncated_normal( [38912, 512], stddev = 0.1 ),\n",
    "            activation_fn = tf.nn.relu\n",
    "        )\n",
    "\n",
    "        hidden_layer_three = tf.nn.dropout( hidden_layer_three, 0.1 )\n",
    "        final_fully_connected = tf.contrib.layers.fully_connected(\n",
    "            hidden_layer_three,\n",
    "            120,\n",
    "            weights_initializer = lambda i, dtype: tf.truncated_normal( [512, 120], stddev = 0.1 )\n",
    "        )\n",
    "        \n",
    "        self._total_loss = self.loss( feature_batch, label_batch )\n",
    "\n",
    "        learning_rate = 0.01\n",
    "        return tf.train.GradientDescentOptimizer( learning_rate ).minimize( self._total_loss )\n",
    "\n",
    "    \n",
    "    def evaluate(self, test_features, test_label):\n",
    "        echo_tensor(self._sess, self._W, 'At evaluate, the _W')\n",
    "        echo_tensor(self._sess, self._b, 'At evaluate, the _b')\n",
    "        echo_tensor(self._sess, test_features, 'At evaluate, test_features')\n",
    "        echo_tensor(self._sess, test_label, 'At evaluate, test_label')\n",
    "        \n",
    "        label_predicted = tf.cast( tf.arg_max(self.inference(test_features), 1), tf.int32 )\n",
    "        \n",
    "        evaluate_result = tf.reduce_mean(tf.cast(tf.equal(label_predicted, test_label), tf.float32))\n",
    "        evaluate_result = tf.Print( evaluate_result, [evaluate_result], '*********** evaluate_result: ' )\n",
    "        return evaluate_result\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    one_ml = ML_CNN([250, 151, 1], 65)\n",
    "    # data from: https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "    one_ml.do_train( 10, ['train'] )  # 10000 次可以得到 80% 的准确率\n",
    "\n",
    "    one_ml.do_evaluate( ['test'] )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function convolution2d in module tensorflow.contrib.layers.python.layers.layers:\n",
      "\n",
      "convolution2d(inputs, num_outputs, kernel_size, stride=1, padding='SAME', activation_fn=<function relu at 0x7f7bf146c840>, normalizer_fn=None, normalizer_params=None, weights_initializer=<function variance_scaling_initializer.<locals>._initializer at 0x7f7bf07ee620>, weights_regularizer=None, biases_initializer=<function zeros_initializer at 0x7f7bf15a4400>, biases_regularizer=None, reuse=None, variables_collections=None, outputs_collections=None, trainable=True, scope=None)\n",
      "    Adds a 2D convolution followed by an optional batch_norm layer.\n",
      "    \n",
      "    `convolution2d` creates a variable called `weights`, representing the\n",
      "    convolutional kernel, that is convolved with the `inputs` to produce a\n",
      "    `Tensor` of activations. If a `normalizer_fn` is provided (such as\n",
      "    `batch_norm`), it is then applied. Otherwise, if `normalizer_fn` is\n",
      "    None and a `biases_initializer` is provided then a `biases` variable would be\n",
      "    created and added the activations. Finally, if `activation_fn` is not `None`,\n",
      "    it is applied to the activations as well.\n",
      "    \n",
      "    Args:\n",
      "      inputs: a 4-D tensor  `[batch_size, height, width, channels]`.\n",
      "      num_outputs: integer, the number of output filters.\n",
      "      kernel_size: a list of length 2 `[kernel_height, kernel_width]` of\n",
      "        of the filters. Can be an int if both values are the same.\n",
      "      stride: a list of length 2 `[stride_height, stride_width]`.\n",
      "        Can be an int if both strides are the same. Note that presently\n",
      "        both strides must have the same value.\n",
      "      padding: one of `VALID` or `SAME`.\n",
      "      activation_fn: activation function.\n",
      "      normalizer_fn: normalization function to use instead of `biases`. If\n",
      "        `normalize_fn` is provided then `biases_initializer` and\n",
      "        `biases_regularizer` are ignored and `biases` are not created nor added.\n",
      "      normalizer_params: normalization function parameters.\n",
      "      weights_initializer: An initializer for the weights.\n",
      "      weights_regularizer: Optional regularizer for the weights.\n",
      "      biases_initializer: An initializer for the biases. If None skip biases.\n",
      "      biases_regularizer: Optional regularizer for the biases.\n",
      "      reuse: whether or not the layer and its variables should be reused. To be\n",
      "        able to reuse the layer scope must be given.\n",
      "      variables_collections: optional list of collections for all the variables or\n",
      "        a dictionay containing a different list of collection per variable.\n",
      "      outputs_collections: collection to add the outputs.\n",
      "      trainable: If `True` also add variables to the graph collection\n",
      "        `GraphKeys.TRAINABLE_VARIABLES` (see tf.Variable).\n",
      "      scope: Optional scope for `variable_op_scope`.\n",
      "    \n",
      "    Returns:\n",
      "      a tensor representing the output of the operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.contrib.layers.convolution2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from img_to_tf_record import Img2TFRecord\n",
    "\n",
    "one_Set = Img2TFRecord('/home/yangyuqi/Downloads/Images', '/tmp/tf_out/tmp1')\n",
    "\n",
    "image_batch, label_batch = one_Set.read_train_images_from_tf_records([250, 151, 1], 5)\n",
    "init = tf.initialize_all_variables()   # tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    coord = tf.train.Coordinator() \n",
    "    threads = tf.train.start_queue_runners( sess = sess, coord = coord )\n",
    "\n",
    "    \n",
    "         for i in range(3):\n",
    "            img, lab = sess.run([image_batch, label_batch])\n",
    "            print(img.shape, lab)\n",
    "\n",
    "    \n",
    "    conv2d_layer_one = tf.contrib.layers.convolution2d(\n",
    "        image_batch, \n",
    "        num_outputs = 32, \n",
    "        kernel_size = (5, 5), \n",
    "        activation_fn = tf.nn.relu,\n",
    "        weights_initializer = tf.random_normal_initializer,\n",
    "        stride = (2, 2),\n",
    "        data_format = 'NHWC',\n",
    "        trainable = True\n",
    "    )\n",
    "\n",
    "    pool_layer_one = tf.nn.max_pool(conv2d_layer_one,\n",
    "                                   ksize = [1, 2, 2, 1],\n",
    "                                   strides = [1, 2, 2, 1],\n",
    "                                   padding = 'SAME')\n",
    "\n",
    "    print( conv2d_layer_one.get_shape() )\n",
    "    print( pool_layer_one.get_shape() )\n",
    "    \n",
    "    \n",
    "    conv2d_layer_two = tf.contrib.layers.convolution2d(\n",
    "        pool_layer_one, \n",
    "        num_outputs = 64, \n",
    "        kernel_size = (5, 5), \n",
    "        activation_fn = tf.nn.relu,\n",
    "        weights_initializer = tf.random_normal_initializer,\n",
    "        stride = (1, 1),\n",
    "        trainable = True\n",
    "    )\n",
    "\n",
    "    pool_layer_two = tf.nn.max_pool(conv2d_layer_two,\n",
    "                                   ksize = [1, 2, 2, 1],\n",
    "                                   strides = [1, 2, 2, 1],\n",
    "                                   padding = 'SAME')\n",
    "\n",
    "    print( conv2d_layer_two.get_shape() )\n",
    "    print( pool_layer_two.get_shape() )\n",
    "    \n",
    "\n",
    "    flattened_layer_two = tf.reshape( pool_layer_tow, [batch_size, -1] )\n",
    "    print( flattened_layer_two.get_shape() )\n",
    "\n",
    "    hidden_layer_three = tf.contrib.layers.fully_connected(\n",
    "        flattened_layer_two, \n",
    "        512,\n",
    "        weight_init = lambda i, dtype: tf.truncated_normal( [38912, 512], stddev = 0.1 ),\n",
    "        activation_fn = tf.nn.relu\n",
    "    )\n",
    "\n",
    "    hidden_layer_three = tf.nn.dropout( hidden_layer_three, 0.1 )\n",
    "    final_fully_connected = tf.contrib.layers.fully_connected(\n",
    "        hidden_layer_three,\n",
    "        120,\n",
    "        weight_init = lambda i, dtype: tf.truncated_normal( [512, 120], stddev = 0.1 )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    for step in range(1000):    # 实际训练闭环 \n",
    "        if coord.should_stop():\n",
    "            print('---- coord should stop ----')\n",
    "            break\n",
    "\n",
    "        sess.run([final_fully_connected])\n",
    "\n",
    "        # 查看训练过程损失递减\n",
    "        if step % 10 == 0:\n",
    "            echo_tensor( self._sess, features, 'features_' + str(step) )\n",
    "            echo_tensor( self._sess, label, 'label_' + str(step) )\n",
    "            echo_tensor( self._sess, total_loss, 'step_' + str(step) + ' loss: ' )\n",
    "\n",
    "            #print( str(training_steps) + \" final loss: \", sess.run([total_loss]) )\n",
    "            echo_tensor( self._sess, total_loss, 'training end. step_' + str(step) + ' final loss: ' )\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "            save_path = saver.save( self._sess, self.__save_path )\n",
    "            print('save_path is: ', save_path)\n",
    "\n",
    "            # 模型评估\n",
    "            evaluate_result = self.evaluate( features, label ) \n",
    "            echo_tensor( self._sess, evaluate_result, 'evaluate_result' )   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    #关闭线程  \n",
    "    coord.request_stop()  \n",
    "    coord.join(threads)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
